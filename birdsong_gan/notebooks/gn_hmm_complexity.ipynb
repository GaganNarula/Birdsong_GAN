{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naval-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hmmlearn\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import joblib\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "meaning-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dangerous-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "speaking-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "specific-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "equivalent-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "occupational-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "birdpath = '/media/songbird/datapartition/mdgan_output/daily_gan/p20r16_nz12_alldaysnets_ngf64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "narrative-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 'day_20'\n",
    "hidden_state = '100'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-stopping",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "challenging-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(join(birdpath, day, 'hmm_hiddensize_'+hidden_state, 'model_'+day+'.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "homeless-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "figured-chase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "planned-success",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = joblib.load(join(birdpath, day, 'hmm_hiddensize_60', 'model_'+day+'.pkl'))\n",
    "model2 = model2['model']\n",
    "model2.n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-building",
   "metadata": {},
   "source": [
    "# get sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ambient-premises",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/songbird/datapartition/mdgan_output/daily_gan/p20r16_nz12_alldaysnets_ngf64/day_20/hmm_hiddensize_100/data_and_scores_day_20.pkl'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pkl_path = glob(join(birdpath, day, 'hmm_hiddensize_'+hidden_state, 'data_and_scores*'))[0]\n",
    "data_pkl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "driving-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joblib.load(data_pkl_path)\n",
    "ztrain = data['ztrain']\n",
    "ztest = data['ztest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "empirical-adrian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841 211\n"
     ]
    }
   ],
   "source": [
    "print(len(ztrain), len(ztest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "brutal-rates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ztrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-friend",
   "metadata": {},
   "source": [
    "# least visited states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "general-toolbox",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 1*model.transmat_\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "excellent-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_sums = T.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "comprehensive-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12146723951012253"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(column_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "elder-salmon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 100 artists>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(T.shape[0]), sorted(column_sums))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-mortality",
   "metadata": {},
   "source": [
    "# can we reduce the dimensionality of the hmm without losing likelihood points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "municipal-marsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..... original logL = 186.471 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting a model with 12176 free scalar parameters with only 12000 data points will result in a degenerate solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..... merged states 19 and 28 .....\n",
      "..... new logL = 137.371 .....\n",
      "..... merged states 0 and 98 .....\n",
      "..... new logL = 110.724 .....\n",
      "..... merged states 20 and 64 .....\n",
      "..... new logL = 109.086 .....\n",
      "..... merged states 7 and 68 .....\n",
      "..... new logL = 107.605 .....\n",
      "..... merged states 4 and 29 .....\n",
      "..... new logL = 105.703 .....\n",
      "..... merged states 67 and 79 .....\n",
      "..... new logL = 102.558 .....\n",
      "..... merged states 24 and 46 .....\n",
      "..... new logL = 98.294 .....\n",
      "..... merged states 55 and 67 .....\n",
      "..... new logL = 90.887 .....\n",
      "..... merged states 3 and 82 .....\n",
      "..... new logL = 89.839 .....\n",
      "..... merged states 53 and 83 .....\n",
      "..... new logL = 55.276 .....\n"
     ]
    }
   ],
   "source": [
    "new_model = reduce_model(model, ztrain, iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "charitable-blackberry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1157412806084714"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logL2 = get_normalized_scores(model2, ztest)\n",
    "logL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "located-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting a model with 12176 free scalar parameters with only 12000 data points will result in a degenerate solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..... original logL = 172.220 .....\n",
      "..... dropped state 48 .....\n",
      "..... new logL = 167.295 .....\n",
      "..... dropped state 38 .....\n",
      "..... new logL = 164.976 .....\n",
      "..... dropped state 20 .....\n",
      "..... new logL = 161.071 .....\n",
      "..... dropped state 93 .....\n",
      "..... new logL = 159.605 .....\n",
      "..... dropped state 36 .....\n",
      "..... new logL = 157.927 .....\n",
      "..... dropped state 65 .....\n",
      "..... new logL = 155.968 .....\n",
      "..... dropped state 56 .....\n",
      "..... new logL = 140.493 .....\n",
      "..... dropped state 8 .....\n",
      "..... new logL = 138.991 .....\n",
      "..... dropped state 35 .....\n",
      "..... new logL = 137.817 .....\n",
      "..... dropped state 31 .....\n",
      "..... new logL = 136.649 .....\n",
      "..... dropped state 15 .....\n",
      "..... new logL = 129.543 .....\n",
      "..... dropped state 46 .....\n",
      "..... new logL = 128.151 .....\n",
      "..... dropped state 20 .....\n",
      "..... new logL = 125.280 .....\n",
      "..... dropped state 58 .....\n",
      "..... new logL = 120.858 .....\n",
      "..... dropped state 73 .....\n",
      "..... new logL = 119.073 .....\n",
      "..... dropped state 37 .....\n",
      "..... new logL = 101.043 .....\n",
      "..... dropped state 40 .....\n",
      "..... new logL = 98.893 .....\n",
      "..... dropped state 54 .....\n",
      "..... new logL = 95.006 .....\n",
      "..... dropped state 29 .....\n",
      "..... new logL = 91.723 .....\n",
      "..... dropped state 36 .....\n",
      "..... new logL = 88.784 .....\n",
      "..... dropped state 5 .....\n",
      "..... new logL = 83.653 .....\n",
      "..... dropped state 25 .....\n",
      "..... new logL = 80.920 .....\n",
      "..... dropped state 74 .....\n",
      "..... new logL = 75.523 .....\n",
      "..... dropped state 58 .....\n",
      "..... new logL = 71.544 .....\n",
      "..... dropped state 24 .....\n",
      "..... new logL = 59.031 .....\n",
      "..... dropped state 57 .....\n",
      "..... new logL = 52.271 .....\n",
      "..... dropped state 32 .....\n",
      "..... new logL = 43.392 .....\n",
      "..... dropped state 18 .....\n",
      "..... new logL = 20.485 .....\n",
      "..... dropped state 55 .....\n",
      "..... new logL = 1.957 .....\n",
      "..... dropped state 57 .....\n",
      "..... new logL = -14.251 .....\n"
     ]
    }
   ],
   "source": [
    "new_model = reduce_model_by_dropstate(model, ztest, iters=30, prob_thresh=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "missing-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_model(model, data, iters=10):\n",
    "    \n",
    "    new_model = model\n",
    "    \n",
    "    logL = get_normalized_scores(new_model, data, False)\n",
    "    print('..... original logL = %.3f .....'%(logL))\n",
    "    \n",
    "    for i in range(iters):\n",
    "        \n",
    "        # find wasserstein distance between all gaussians\n",
    "        D, inds = distance_matrix(new_model)\n",
    "        idx = np.argmin(D)\n",
    "        i_j = list(inds[idx])\n",
    "        \n",
    "        new_model = merge_states(new_model, *i_j)\n",
    "        print('..... merged states %d and %d .....'%(i_j[0], i_j[1]))\n",
    "        \n",
    "        logL = get_normalized_scores(new_model, data, False)\n",
    "        print('..... new logL = %.3f .....'%(logL))\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "minor-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_model_by_dropstate(model, data, iters=10, prob_thresh=0.2):\n",
    "    \n",
    "    new_model = model\n",
    "    \n",
    "    logL = get_normalized_scores(new_model, data, False)\n",
    "    print('..... original logL = %.3f .....'%(logL))\n",
    "    \n",
    "    for i in range(iters):\n",
    "        \n",
    "        # find least visited state\n",
    "        T = new_model.transmat_.sum(axis=0)\n",
    "        \n",
    "        idx = np.argmin(T)\n",
    "        print('...... prob=%.3f ......'%(T[idx]))\n",
    "        if T[idx] > prob_thresh:\n",
    "            print('...... probability threshold exceeded, stopping ......')\n",
    "            break\n",
    "            \n",
    "        new_model = drop_state(new_model, idx)\n",
    "        print('..... dropped state %d .....'%(idx))\n",
    "        \n",
    "        logL = get_normalized_scores(new_model, data, False)\n",
    "        print('..... new logL = %.3f .....'%(logL))\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "executed-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_scores(model, seqs, normalize_by_length=True):\n",
    "    \"\"\"Normalized loglikelihood score\"\"\"\n",
    "    LogL = 0.\n",
    "    for n in range(len(seqs)):\n",
    "        \n",
    "        ll = model.score(seqs[n]) \n",
    "        \n",
    "        if normalize_by_length:\n",
    "            ll /= seqs[n].shape[0]\n",
    "            \n",
    "        LogL += ll\n",
    "    return LogL / len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "considered-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein(mu1, mu2, cov1, cov2):\n",
    "    C2_sqrt = sqrtm(cov2)\n",
    "    term1 = ((mu1-mu2)**2).sum()\n",
    "    term2 = np.trace(cov1 + cov2 - (2 * sqrtm(C2_sqrt @ (cov1 @ C2_sqrt))))\n",
    "    return term1 + term2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "official-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix(model):\n",
    "    nstates = model.n_components\n",
    "    \n",
    "    D = []\n",
    "    indices = []\n",
    "    for i in range(nstates):\n",
    "        for j in range(i+1, nstates):\n",
    "            result = wasserstein(model.means_[i], model.means_[j], model.covars_[i], model.covars_[j]) \n",
    "            D.append(result)\n",
    "            indices.append([i, j])\n",
    "    return np.array(D), np.array(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "senior-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, inds = distance_matrix(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "every-variation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4950,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "external-memphis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4591"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ordered-blanket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.281121430045644"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D[4591]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "nominated-treasury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 28])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds[np.argmin(D)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "competitive-cooling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "floral-petite",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting a model with 12176 free scalar parameters with only 12000 data points will result in a degenerate solution.\n"
     ]
    }
   ],
   "source": [
    "new_model = merge_states(model, 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "owned-sunday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99,)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.startprob_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "taken-stack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.39297373395746"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.score(ztrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "numerous-rotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_stationary_distribution().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "respective-ballet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a = merge_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "light-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first the startprob\n",
    "def merge_states(model, i, j):\n",
    "    \n",
    "    A = 1.*model.transmat_\n",
    "    pi = 1. * model.startprob_\n",
    "    p_merge = pi[i] + pi[j]\n",
    "    pi = np.delete(pi, [i,j],axis=0)\n",
    "    pi = np.append(pi, p_merge)\n",
    "    \n",
    "    # incoming paths to i and j\n",
    "    p_merge = A[:,i] + A[:,j]\n",
    "    p_merge = p_merge.reshape(-1,1)\n",
    "    \n",
    "    # remove original\n",
    "    T = np.delete(A, [i,j], axis=1)\n",
    "    # make new column\n",
    "    T = np.concatenate([T, p_merge], axis=1)\n",
    "    \n",
    "    # outgoing paths from i and j\n",
    "    p_i, p_j = T[i,:], T[j,:]  \n",
    "    mix_prob = 0.5*(p_i + p_j)\n",
    "    mix_prob = mix_prob.reshape(1,-1)\n",
    "    T = np.delete(T, [i, j], axis=0)\n",
    "    T = np.concatenate([T, mix_prob], axis=0)\n",
    "\n",
    "    # now drop the means and covs\n",
    "    means = 1.*model.means_\n",
    "    covars = 1.*model.covars_\n",
    "    if model.covariance_type == 'diag':\n",
    "        covars = np.stack([np.diag(c) for c in covars])\n",
    "        \n",
    "    mu1 = means[i]\n",
    "    mu2 = means[j]\n",
    "    cov1 = covars[i]\n",
    "    cov2 = covars[j]\n",
    "        \n",
    "    new_mu = 0.5*(mu1 + mu2)\n",
    "    new_mu = new_mu.reshape(1,-1)\n",
    "    new_cov = cov1 + cov2\n",
    "    if model.covariance_type=='diag':\n",
    "        new_cov = new_cov.reshape(1, -1)\n",
    "    else:\n",
    "        new_cov = new_cov.reshape(1, new_cov.shape[0], new_cov.shape[1])\n",
    "    \n",
    "    means = np.delete(means, [i,j], axis=0)\n",
    "    covars = np.delete(covars, [i,j], axis=0)\n",
    "    \n",
    "    means = np.concatenate([means, new_mu],axis=0)\n",
    "    covars = np.concatenate([covars, new_cov],axis=0)\n",
    "    \n",
    "    # new model\n",
    "    new_model = GaussianHMM(n_components=model.n_components - 1,\n",
    "                           covariance_type=model.covariance_type)\n",
    "    # fit with random\n",
    "    fake_init_data = np.random.multivariate_normal(mean=np.zeros(model.n_features),\n",
    "                                                        cov=np.eye(model.n_features), \n",
    "                                                        size = 1000)\n",
    "    new_model._init(fake_init_data)\n",
    "    new_model.means_ = means\n",
    "    new_model.covars_ = covars\n",
    "    new_model.transmat_ = T\n",
    "    new_model.startprob_ = np.array(pi)\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "separated-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_state(model, i):\n",
    "    '''\n",
    "    This function drops the state \"drop_state\" from the start-probability and the transition matrix\n",
    "    Then it redistributes the probability mass over the other entries\n",
    "    '''\n",
    "    A = 1.*model.transmat_\n",
    "    pi = 1. * model.startprob_\n",
    "    K = model.n_components\n",
    "    \n",
    "    # first the startprob\n",
    "    p_drop = pi[i]\n",
    "    # divide by number of remaining states\n",
    "    p_add = p_drop / (K - 1)\n",
    "    \n",
    "    # add to remaining \n",
    "    pi = np.delete(pi, i)\n",
    "    pi += p_add\n",
    "\n",
    "    # now transition matrix\n",
    "    # extract the mass from the drop_state column\n",
    "    p_drop_column = A[:, i]\n",
    "    # loop over rows (states)\n",
    "    for k in range(K):\n",
    "        if k != i:\n",
    "            p_add = p_drop_column[k]/(K - 1)\n",
    "            idss = np.arange(K)\n",
    "            A[k, idss!=i] += p_add\n",
    "            \n",
    "    # drop the column\n",
    "    A = np.delete(A, i, 1)\n",
    "    \n",
    "    # drop the row\n",
    "    A = np.delete(A, i, 0)\n",
    "    \n",
    "    # now drop the means\n",
    "    means = 1.*model.means_\n",
    "    covars = 1.*model.covars_\n",
    "    if model.covariance_type == 'diag':\n",
    "        covars = np.stack([np.diag(c) for c in covars])\n",
    "    \n",
    "    means = np.delete(means, i, 0)\n",
    "    # drop the covariances\n",
    "    covars = np.delete(covars, i, 0)\n",
    "    \n",
    "    # reduce the number of states\n",
    "    # new model\n",
    "    new_model = GaussianHMM(n_components=model.n_components - 1,\n",
    "                           covariance_type=model.covariance_type)\n",
    "    # fit with random\n",
    "    fake_init_data = np.random.multivariate_normal(mean=np.zeros(model.n_features),\n",
    "                                                        cov=np.eye(model.n_features), \n",
    "                                                        size = 1000)\n",
    "    new_model._init(fake_init_data)\n",
    "    new_model.means_ = means\n",
    "    new_model.covars_ = covars\n",
    "    new_model.transmat_ = A\n",
    "    new_model.startprob_ = pi\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "turned-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = GaussianHMM(n_components=model.n_components,\n",
    "                           covariance_type=model.covariance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "pursuant-thomas",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting a model with 12399 free scalar parameters with only 1200 data points will result in a degenerate solution.\n"
     ]
    }
   ],
   "source": [
    "new_model._init(np.random.multivariate_normal(mean=np.zeros(model.n_features),\n",
    "                                                        cov=np.eye(model.n_features), \n",
    "                                                        size = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "wrong-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.startprob_ = np.random.dirichlet(np.ones(100)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "still-mother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.startprob_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "empirical-davis",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-4b3b98aba8aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mztrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-179-4b3b98aba8aa>\u001b[0m(1)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mztrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "_, s = new_model.score(ztrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-soldier",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
